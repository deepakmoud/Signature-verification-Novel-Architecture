{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_Sf8lLdMYsCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 13:28:37.280174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D,MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "image_shape=(224,224,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'kerasbackend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142223/2399162806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkerasbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'kerasbackend'"
     ]
    }
   ],
   "source": [
    "tf.kerasbackend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzwJF19Y0ct",
    "outputId": "8e7499f7-220f-4aa9-cfbd-4862660af42c"
   },
   "outputs": [],
   "source": [
    "# Updating Keras\n",
    "!pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90n6dcKIY3by",
    "outputId": "cedf7dca-b104-48ee-a80f-c7e41f8596c5"
   },
   "outputs": [],
   "source": [
    "#Load the pretrained Network\n",
    "#vgg16_model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_height,img_width,3), pooling=None, classes=1000)\n",
    "\n",
    "vgg16_model=tf.keras.applications.VGG16(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                             weights='imagenet')\n",
    "print(\"pretrained Network is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yed6-8x8Y6bM",
    "outputId": "97745381-791e-4a8a-afcb-c1663f2aec22"
   },
   "outputs": [],
   "source": [
    "# Freeze the layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "print(\"Pretrained layers are freezed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 13:29:36.291185: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-10 13:29:36.293161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-10 13:29:36.371682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-10 13:29:36.371743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-10 13:29:36.392806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-10 13:29:36.392940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-10 13:29:36.406064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-10 13:29:36.409094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-10 13:29:36.430643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-10 13:29:36.435303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-10 13:29:36.473523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-10 13:29:36.474577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-02-10 13:29:36.475570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-10 13:29:36.480699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-10 13:29:36.480748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-10 13:29:36.480788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-10 13:29:36.480814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-10 13:29:36.480840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-10 13:29:36.480865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-10 13:29:36.480891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-10 13:29:36.480915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-10 13:29:36.480941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-10 13:29:36.481682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-02-10 13:29:36.481981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-10 13:29:37.512536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-10 13:29:37.512573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-02-10 13:29:37.512580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-02-10 13:29:37.513494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 45378 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:18:00.0, compute capability: 7.5)\n",
      "2022-02-10 13:29:37.514532: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All layers top of pretrained layers are developed\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu'))\n",
    "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
    "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
    "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
    "print(\"All layers top of pretrained layers are developed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(96, kernel_size=(3,3), strides= 4, padding= 'valid', \n",
    "                 activation= 'relu', input_shape=(224,224,3), kernel_initializer= 'he_normal')) \n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', data_format= None))\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)\n",
    "          \n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)\n",
    "          \n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)\n",
    "          \n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu'))\n",
    "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
    "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
    "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
    "print(\"All layers top of pretrained layers are developed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9nrTOYx5t12",
    "outputId": "3e1f3607-7ab2-4cb0-fec5-ce7af519d797"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.add(Conv2D(96, kernel_size=(3,3), strides= 4, padding= 'valid', \n",
    "                 activation= 'relu', input_shape=(224,224,3), kernel_initializer= 'he_normal')) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', data_format= None))\n",
    "\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu'))\n",
    "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
    "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
    "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
    "print(\"All layers top of pretrained layers are developed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCoKydhAn-6L"
   },
   "source": [
    "https://www.kaggle.com/blurredmachine/alexnet-architecture-a-complete-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJJplrQeZDKx",
    "outputId": "838d3874-9eaf-4083-c6c9-effb76f3d3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input parameters are assigned\n"
     ]
    }
   ],
   "source": [
    "# Input parameter\n",
    "#train_data_dir ='/content/drive/My Drive/Colab Notebooks/Dataset GDPS/train_dir'\n",
    "train_data_dir='/home/poornima/Data/GDPS DATASET/train_dir/'\n",
    "val_data_dir ='/home/poornima/Data/GDPS DATASET/val_dir/'\n",
    "model_weights_file = '/home/poornima/Data/GDPS DATASET/model_vgg16_weights.hdf5'\n",
    "nb_epochs = 50\n",
    "print(\"Input parameters are assigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(96, kernel_size=(11,11), strides= 1, padding= 'valid', \n",
    "                 activation= 'relu', input_shape=(224,224,3), kernel_initializer= 'he_normal')) \n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', data_format= None))\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu'))\n",
    "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
    "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
    "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
    "print(\"All layers top of pretrained layers are developed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13L22j2RZHrq",
    "outputId": "eeb66893-0e2c-42e5-fee2-412689d4ebe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Complied\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Model is Complied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48tUhIKiZMvm",
    "outputId": "d0128913-1b64-4aeb-8539-52b18c0c9faf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNuqzITRZPn8",
    "outputId": "ff47b9e1-ba3b-4d4e-c9fd-beaa4e7fb8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 172800 images belonging to 2 classes.\n",
      "Found 43200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image data generation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "img_width, img_height = 224, 224\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
    "                                                    batch_size=16,shuffle=False, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
    "                                                    batch_size=16,shuffle=False,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9A93j5hMZVg_",
    "outputId": "2d0bad13-1476-485a-da35-77c3648057ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 13:31:13.176092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-10 13:31:13.178616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 13:31:14.103531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-10 13:31:14.432982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-10 13:31:15.777317: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-02-10 13:31:15.866172: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4484/10800 [===========>..................] - ETA: 19:28 - loss: 16.0296 - accuracy: 0.5375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 13:45:33.532194: W tensorflow/core/framework/op_kernel.cc:1751] Unknown: UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n",
      "    img = load_img(filepaths[j],\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "\n",
      "  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n",
      "    raise UnidentifiedImageError(\n",
      "\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\nTraceback (most recent call last):\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\nTraceback (most recent call last):\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2041]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7777/1451221815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Completed!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\nTraceback (most recent call last):\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\nTraceback (most recent call last):\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/poornima/anaconda3/envs/keras/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fb399ea9e50>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2041]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history = model.fit(train_generator, epochs=nb_epochs, validation_data=validation_generator)\n",
    "\n",
    "print('Training Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "66v0MvyvZZDW",
    "outputId": "98984b6d-74fe-43a7-a011-6145b6ef1c31"
   },
   "outputs": [],
   "source": [
    " # save model and architecture to single file\n",
    "model.save('/home/poornima/Data/ GDPS DATASET/novel_model_verification_GDPS.h5')\n",
    "model.summary()\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YFq0H2-BZcjS",
    "outputId": "d34179f6-9cc1-4d4f-8779-a91bf775d909"
   },
   "outputs": [],
   "source": [
    "# save weights to single file\n",
    "model.save_weights('/home/poornima/Data/ GDPS DATASET/novel_model_verification_weights_GDPS.h5')\n",
    "print(\"Weights saved in local  Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "WZAi-ofxZgR8",
    "outputId": "c719fec6-0ed3-458f-a837-db040ccb9875"
   },
   "outputs": [],
   "source": [
    "# Loading saved model from Drive.\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/home/poornima/Data/ GDPS DATASET/novel_model_verification_weights_GDPS.h5')\n",
    "print(\"Model is Loaded\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ycbMLOcjZnmk",
    "outputId": "b8692643-72dd-420a-a35a-60675678fdab"
   },
   "outputs": [],
   "source": [
    "# Extracting Features from classification Layer\n",
    "from tensorflow.keras.models import Model\n",
    "layer_name= 'classification_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "print(\"Imtermediate model is constructed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "nb3rfV35Z0nr",
    "outputId": "e945cc01-064d-4ed8-b25e-bc857247f94a"
   },
   "outputs": [],
   "source": [
    "# Compilation of intermediate model\n",
    "intermediate_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Model is Complied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "mjU09Es5Z4Fp",
    "outputId": "3ac70a4d-938b-42d4-dcbf-bc51aac2dc5a"
   },
   "outputs": [],
   "source": [
    "# Saving intermediate model\n",
    "intermediate_layer_model.save('/home/poornima/Data/ GDPS DATASET/intermediate_model_vgg16_GDPS.h5')\n",
    "intermediate_layer_model.summary()\n",
    "\n",
    "print(\"Saved Intermediate model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_TqY_4BnZ8PX",
    "outputId": "bd8dc019-bf2d-46db-cb68-c3ca6aa97faa"
   },
   "outputs": [],
   "source": [
    "# Loading Intermediate Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('/home/poornima/Data/ GDPS DATASET/intermediate_model_vgg16_GDPS.h5')\n",
    "print(\"Intermediate model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-L31_WFZaB1L",
    "outputId": "add94d2d-b95e-4f7d-db42-bb9550b4cafa"
   },
   "outputs": [],
   "source": [
    "# Training Label feature identification(y_train)\n",
    "\n",
    "batch_size=32\n",
    "sample_count=18016\n",
    "features = np.zeros(shape=(18016, 64))  # Must be equal to the output of the convolutional base\n",
    "labels = np.zeros(shape=(18016))\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "   features_batch = model.predict(inputs_batch)\n",
    "   features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "   labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "   i += 1\n",
    "   if i*batch_size  >= sample_count:\n",
    "     break\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "uTKFifVGaH-D",
    "outputId": "e1dc350a-53d6-4e57-a08f-d70706a24ec8"
   },
   "outputs": [],
   "source": [
    "#identification of training Labels\n",
    "features_train=features\n",
    "print(features_train.shape)\n",
    "labels_train=np.expand_dims(labels, axis=1)\n",
    "print(labels_train.shape)\n",
    "print(labels_train)\n",
    "print(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "zuqyZ1VjaLMJ",
    "outputId": "f5e00603-cdc1-47d9-b305-1e34e60f532c"
   },
   "outputs": [],
   "source": [
    "# identification of test labels\n",
    "import numpy as np\n",
    "batch_size=32\n",
    "sample_count=3584\n",
    "features_test = np.zeros(shape=(3584, 64))  # Must be equal to the output of the convolutional base\n",
    "labels_test = np.zeros(shape=(3584))\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in validation_generator:\n",
    "   features_batch = model.predict(inputs_batch)\n",
    "   features_test[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "   labels_test[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "   i += 1\n",
    "   if i*batch_size  >= sample_count:\n",
    "     break\n",
    "print(labels_test.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "3sxB-SqcaPTV",
    "outputId": "0e7e7f5e-25d8-4acf-e720-752fd3d072df"
   },
   "outputs": [],
   "source": [
    "# #identification of testing Labels\n",
    "print(features_test.shape)\n",
    "labels_test=np.expand_dims(labels_test, axis=1)\n",
    "print(labels_test.shape)\n",
    "print(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "cXPaTjNEaTDO",
    "outputId": "38295c87-9bc9-4fc0-a4b5-4bbd80e022ed"
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train,labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "tK7WfMXhaWy5",
    "outputId": "7a1e7f87-2353-4c21-c73c-6453a7ff3849"
   },
   "outputs": [],
   "source": [
    "# Kernel SVM\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting KernelSVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "lRNFNMveaah7",
    "outputId": "f088fe27-7e58-4bab-fe4e-07fc044ae0c4"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting KernelSVM to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "yv2jInXOakFa",
    "outputId": "db39c23e-c34d-4282-a9fb-5bcf37c68f5f"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting KernelSVM to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "bu_p4Ux7apAA",
    "outputId": "e7604cbe-2444-4215-b4da-a387a73f32cf"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting KernelSVM to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "YnfeZ4eVavhm",
    "outputId": "2829fe02-479b-4aee-a9e8-b480a44fd5a4"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "# Fitting KernelSVM to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "qsHQZapTazre",
    "outputId": "20415cfc-f5a5-46f0-a640-df64f0626191"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features_train)\n",
    "X_test = sc.transform(features_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, labels_train.ravel())\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "# calculate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# calculate precision\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision = precision_score(labels_test, y_pred, average='binary')\n",
    "print('Precision: %.3f' % (precision*100))\n",
    "# calculate recall\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "recall = recall_score(labels_test, y_pred, average='binary')\n",
    "print('Recall: %.3f' % (recall*100))\n",
    "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "# calculate score\n",
    "score = f1_score(labels_test, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "f7EDeFata22V",
    "outputId": "d128b41e-4efa-4322-fc24-ec9160e7099e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('/home/poornima/Data/Dataset GDPS-20220127T080751Z-001/Dataset GDPS/model_vgg16_GDPS.h5')\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(validation_generator)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "3bb62a57242e42c5a1d64b5a22be1aa0",
      "05a69fe882d447d094157958ab8e9bc9",
      "6f251c500d4048e2a33b2fdd5b1f9e3b",
      "ae39a7caa10e4b0ca753de0771874d07",
      "46c90d206d3f4d29b64a59db3e6f979f"
     ]
    },
    "id": "JLQ8BYGedcbk",
    "outputId": "c288c170-589c-4cb3-bc75-c56b1d70a5b8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "button = widgets.Button(description=\"Click to know category of Image\",  )\n",
    "output = widgets.Output()\n",
    "\n",
    "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_GDPS.h5')\n",
    "img_path = '/content/drive/My Drive/Colab Notebooks/Dataset GDPS/train_dir/forged/cf-001-01.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)\n",
    "print(block4_pool_features)\n",
    "if(block4_pool_features> 0.5):\n",
    "  a= 'Genuine'\n",
    "elif(block4_pool_features< 0.5):\n",
    "  a='forged'\n",
    "def on_button_clicked(b):\n",
    "  # Display the message within the output widget.\n",
    "  with output:\n",
    "    print(\"Image is  \"  + a)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "d51a8019e74344f088a8f7ef974eb613",
      "a52c0dab35c8411f8a1e83686d210415",
      "153a6e590daf47bf92200b4baeb536fc",
      "bed5f74780ae4f8d87800bd1e244be5e",
      "642c7e2437e84b21b937880c574192ea"
     ]
    },
    "id": "ZjRNvlFcI8HY",
    "outputId": "118fba02-fbbf-4d8f-8ded-c081e89ca63d"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "button = widgets.Button(description=\"Click Me!\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "  # Display the message within the output widget.\n",
    "  with output:\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(button, output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Signature Verification  GDPS dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05a69fe882d447d094157958ab8e9bc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "153a6e590daf47bf92200b4baeb536fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "3bb62a57242e42c5a1d64b5a22be1aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Click to know category of Image",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_05a69fe882d447d094157958ab8e9bc9",
      "style": "IPY_MODEL_6f251c500d4048e2a33b2fdd5b1f9e3b",
      "tooltip": ""
     }
    },
    "46c90d206d3f4d29b64a59db3e6f979f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642c7e2437e84b21b937880c574192ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f251c500d4048e2a33b2fdd5b1f9e3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "a52c0dab35c8411f8a1e83686d210415": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae39a7caa10e4b0ca753de0771874d07": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_46c90d206d3f4d29b64a59db3e6f979f",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "Image is  forged\n"
       }
      ]
     }
    },
    "bed5f74780ae4f8d87800bd1e244be5e": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_642c7e2437e84b21b937880c574192ea",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "Button clicked.\n"
       }
      ]
     }
    },
    "d51a8019e74344f088a8f7ef974eb613": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Click Me!",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_a52c0dab35c8411f8a1e83686d210415",
      "style": "IPY_MODEL_153a6e590daf47bf92200b4baeb536fc",
      "tooltip": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
